<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>IJCAI-2019 Tusion Workshop</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.0.0.css" rel="stylesheet">
  </head>
  <body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light">
      <a class="navbar-brand" href="#">IJCAI-2019 Workshop</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item active"> <a class="nav-link" href="#">Home <span class="sr-only">(current)</span></a> </li>
		  <li class="nav-item"> <a class="nav-link" href="#CFP">Call For Papers</a> </li>
		  <li class="nav-item"> <a class="nav-link" href="#Schedule">Schedule</a> </li>
		  <li class="nav-item"> <a class="nav-link" href="#Dates">Important Dates</a> </li>
		  <li class="nav-item"> <a class="nav-link" href="#Organizers">Organizers</a> </li>	
        </ul>
</div>
    </nav>
    <header>
      <div class="jumbotron">
        <div class="container">
          <div class="row">
            <div class="col-10 col-lg-12">
			  <h4 class="text-center">The First International Workshop on </h4>
              <h1 class="text-center"><strong>Bringing Semantic Knowledge into <br> Vision and Text Understanding</strong></h1>
              <h4 class="text-center"><em>In conjunction with IJCAI-2019, Macao, China</em></h4>
              <h4 class="text-center"><em><b>Time: August 11, 2019 Full Day</b></em></h4>
			  <h4 class="text-center"><em><b>Location: Sicily 2503</b></em></h4>
            </div>
          </div>
        </div>
      </div>
	  <div class="container">
	  <div class="row">
          <div class="col-sm-6 col-lg-12">
	  <p class="text-justify">Extracting and understanding the high-level semantic information in vision and text data is considered as one of the key capabilities of effective artificial intelligence (AI) systems, which has been explored in many areas of AI, including computer vision, natural language processing, machine learning, data mining, knowledge representation, etc. Due to the success of deep representation learning, we have observed increasing research efforts in the intersection between vision and language for a better understanding of semantics, such as image captioning, visual question answering, etc. Besides, exploiting external semantic knowledge (e.g., semantic relations, knowledge graphs) for vision and text understanding also deserves more attention: The vast amount of external semantic knowledge could assist in having a “deeper” understanding of vision and/or text data, e.g., describing the contents of images in a more natural way, constructing a comprehensive knowledge graph for movies, building a dialog system equipped with commonsense knowledge, etc.</p>
			  <p class="text-justify">This workshop will provide a forum for researchers to review the recent progress of vision and text understanding, with an emphasis on novel approaches that involve deeper and better semantic understanding of vision and text data. The workshop is targeting a broad audience, including the researchers and practitioners in computer vision, natural language processing, machine learning, data mining, etc.</p>	
	  
	    <img src="Pics/Tusion2019-3.jpeg" alt="" width="360" height="270" class="img-fluid"/> <img src="Pics/Tusion2019-2.jpeg" alt="" width="360" height="270" class="img-fluid"/> <img src="Pics/Tusion2019-1.jpeg" alt="" width="360" height="270" class="img-fluid"/></div>
    </div> 
	</div>	  
	
    </header>
    <section>
      <div class="container">
		<div class="row">
          <div class="col-sm-12 mt-4 mb-2 text-center">
            <h2>Workshop Topics</h2>
          </div>
        </div>
		<div class="row" style="margin-bottom: 3em;">
          <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
				<p class="mb-0 col-lg-11 offset-lg-1">Image and Video Captioning</p>
           </blockquote>
          </div>
          <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
				<p class="mb-0 col-lg-11 offset-lg-1">Visual Question Answering and Visual Dialog</p> 
            </blockquote>
          </div>
          <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
				<p class="mb-0 col-lg-11 offset-lg-1">Scene Graph Generation from Visual Data</p>
            </blockquote>
          </div>
          <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Video Prediction and Reasoning</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Scene Understanding</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Knowledge Graph Construction</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Knowledge Graph Embedding</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Representation Learning</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Question Answering over Knowledge Bases</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Dialog Systems using Knowledge Graph</p>
            </blockquote>
          </div>
	      <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Adversarial Generation of Language & Images</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Graphical Causal Models</p>
            </blockquote>
          </div>
		  <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Multimodal Representation and Fusion</p>
            </blockquote>
          </div>
	      <div class="col-sm-6 col-lg-6">
            <blockquote class="blockquote">
              <p class="mb-0 col-lg-11 offset-lg-1">Transfer Learning across Vision and Text</p>
            </blockquote>
          </div>
        </div>
      </div>
 <div>
  <div class="container"> </div>
  </div>
      <div class="container">
        <div class="row">
          <div class="col-12 mb-2 text-center">
            <h2><a id="CFP">Call For Papers</a></h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-6 col-lg-12" style="margin-bottom: 3em;">
		  <b>Submission Guidelines</b><br>
			  <p>Three types of submissions are invited to the workshop: long papers (up to 7 pages), short papers (up to 4 pages) and demo papers (up to 4 pages).</p>
			  <p>All submissions should be formatted according to the IJCAI'2019 <a href="https://www.ijcai.org/authors_kit" target="_blank">Formatting Instructions and Templates</a>. Authors are required to submit their papers electronically in PDF format to the Microsoft <a href="https://cmt3.research.microsoft.com/TUSION2019" target="_blank">CMT submission site</a>.</p>
			  <p>At least one author of each accepted paper must register for the workshop, and the registration information can be found on the <a href="https://www.ijcai19.org/register.html" target="_blank">IJCAI-2019</a> website. The authors of accepted papers should present their work at the workshop.</p>
			  <p>As in previous years, IJCAI does not have a formal proceeding for workshop papers. All the accepted papers will be made available to the workshop participants.</p>
			  <p>Any question regarding paper submission, please email us: sheng.li[AT]uga.edu or yaliang.li[AT]alibaba-inc.com</p>
            <p> </p>
          </div>
          
        </div>
	<div class="container"> </div>
  </div>
     
		<div class="container">
        <div class="row">
          <div class="col-12 mb-2 text-center">
			  <h2><a id="Schedule">Schedule</a></h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-6 col-lg-12" style="margin-bottom: 3em;">
			<h6 class="text-left"><b>Date</b>: August 11, 2019</h6>
			<h6 class="text-left"><b>Location</b>: Sicily 2503</h6>
            <h6 class="text-left">9:05AM--9:20AM Welcome from Organizers</h6>
			<h6 class="text-left">9:20AM--9:40AM Oral 1: Discovering Medical Entity Relations from Texts using Dependency Information (<a href="Docs/Tusion19/1_Discovering_Medical_Entity_Relations_from_Texts_using_Dependency_Information.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Ying Shen; Jiyue Huang; Jin Zhang; Min Yang; Kai Lei</p>
			<h6 class="text-left">9:40AM--10:00AM Oral 2: Automatic Query Correction for POI Retrieval using Deep and Statistical Collaborative Model (<a href="Docs/Tusion19/2_Automatic_Query_Correction_for_POI Retrieval_using_Deep_and_Statistical_Collaborative_Model.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Canxiang Zhu; Zhiming Chen; Yang Liu; Juan Hu; Shujuan Sun; Bixiao Cheng; Zhendong Yang; Li Ma; Hua Chai</p>
			<h6 class="text-left">10:00AM--10:30AM Coffee Break</h6>
			<h6 class="text-left">10:30AM--11:30AM <b>Keynote I</b>: Video and Language</h6>
			<p class="text-center">Jiebo Luo (University of Rochester)</p>
			<h6 class="text-left">11:30AM--11:50AM Oral 3: Transfer Learning with Domain-aware Attention Network for Item Recommendation in E-commerce (<a href="Docs/Tusion19/3_Transfer_Learning_with_Domain-aware_Attention_Network.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Minghui Qiu; Bo Wang; Cen Chen; Xiaoyi Zeng; Jun Huang</p>
			<h6 class="text-left">11:50AM--12:10PM Oral 4: Compressive Multi-document Summarization with Sense-level Concepts (<a href="Docs/Tusion19/4_Compressive_Multi-document_Summarization_with_Sense-level Concepts.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Xin Shen; Wai Lam; Xunying Liu; Piji Li</p>
			<h6 class="text-left">12:10AM--2:00PM Lunch Break</h6>
			<h6 class="text-left">2:10PM--3:10PM <b>Keynote II</b>: Learning Generalized Transformation Equivariant Representations: A Novel Paradigm of Deep Learning</h6>
			<p class="text-center">Guojun Qi</p>
			<h6 class="text-left">3:10PM--3:30PM Oral 5: Vehicle Semantic Understanding for Automated Driving using Deep Vision-based Features (<a href="Docs/Tusion19/5_Vehicle_Semantic_Understanding.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Vijay John; Seiichi Mita</p>
			<h6 class="text-left">3:40PM--4:00PM Oral 6: Pedestrian Detection via Combined Cascades (<a href="Docs/Tusion19/6_Pedestrian_Detection_via_Combined_Cascades.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Yujia Tang</p>
			<h6 class="text-left">4:00PM--4:30PM Oral 7: Meanings of "Data" and "Rules" Emerge as Actions through Auto-Programming for General Purposes (<a href="Docs/Tusion19/7_Meanings_of_Data_and_Rules_Emerge.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Juyang Weng</p>
			<h6 class="text-left">4:30PM--4:50PM Oral 8: Conformal-Cycle-Consistent Adversarial Model for Video Prediction with Action Control (<a href="Docs/Tusion19/8_Conformal-Cycle-Consistent_Adversarial_Model.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Zhihang Hu; Jason T. L. Wang</p>
			<h6 class="text-left">4:50PM--5:10PM Oral 9: System Demo for Transfer Learning across Vision and Text using Domain Specific CNN Accelerator for On-Device NLP Applications (<a href="Docs/Tusion19/9_DemoNLP_on_Chip.pdf" target="_blank"><b>PDF</b></a>)</h6>
			<p class="text-center">Baohua Sun; Lin Yang; Michael Lin; Wenhan Zhang; Patrick Dong; Charles Young; Jason Dong</p>
			<h6 class="text-left">5:10PM--5:20PM Closing Remarks </h6>
            <p> </p>
          </div>
		</div>
      </div>
		  
		 <div class="container">
        <div class="row">
          <div class="col-12 mb-2 text-center">
            <h2><a id="Dates">Important Dates</a></h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-6 col-lg-12" style="margin-bottom: 3em;">
			<h5><li class="offset-lg-3 col-lg-7">Submission Deadline: April 18, 2019 (11:59PM UTC-12)</li></h5>
			<h5><li class="offset-lg-3 col-lg-7">Notification: May 10, 2019 (11:59PM UTC-12)</li></h5>
            <h5><li class="offset-lg-3 col-lg-7">Camera Ready: June 10, 2019 (11:59PM UTC-12)</li></h5>
            <p> </p>
          </div>
          
        </div>
      </div>
        <div class="row">
          <div class="col-lg-12 mb-4 mt-2 text-center">
            <h2><a id="Organizers">Organizers</a></h2>
          </div>
        </div>
      <div class="container ">
  <div class="row">
          <div class="col-md-6 col-sm-12 text-center col-lg-3" style="margin-bottom: 3em;">
            <img class="rounded-circle" alt="140x140" style="width: 140px; height: 140px;" src="Pics/ShengLi.png" data-holder-rendered="true">
			  <h3><a href="http://www.cs.uga.edu/~shengli" target="_blank">Sheng Li</a></h3>
            <p>Assistant Professor<br>University of Georgia</p>
          </div>
    <div class="col-md-6 col-sm-12 text-center col-lg-3 margin-bottom: 5em">
            <img class="rounded-circle" alt="140x140" style="width: 140px; height: 140px;" src="Pics/YaliangLi.png" data-holder-rendered="true">
		<h3><a href="https://sites.google.com/site/yaliangli/" target="_blank">Yaliang Li</a></h3>
            <p>Research Scientist<br>Alibaba Group</p>
          </div>
    <div class="col-md-6 col-sm-12 text-center col-lg-3">
            <img class="rounded-circle" alt="140x140" style="width: 140px; height: 140px;" src="Pics/JingGao.png" data-holder-rendered="true">
            <h3><a href="https://cse.buffalo.edu/~jing/" target="_blank">Jing Gao</a></h3>
            <p>Associate Professor<br>University at Buffalo</p>
          </div>
    <div class="col-md-6 col-sm-12 text-center col-lg-3">
            <img class="rounded-circle" alt="140x140" style="width: 140px; height: 140px;" src="Pics/YunFu.jpg" data-holder-rendered="true">
            <h3><a href="http://www1.ece.neu.edu/~yunfu/" target="_blank">Yun Fu</a></h3>
            <p>Professor<br>Northeastern University</p>
          </div>
        </div>
        
  <div>
        <div> </div>
</div>
      
      <div class="container">
        <div class="row">
          <div class="col-12 mb-2 text-center">
            <h2>Program Committee</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-sm-6 col-lg-6">
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Daoyuan Chen, Peking University</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Yang Deng, Peking University</p>
		      </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Jiashi Feng, National University of Singapore</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Vishrawas Gopalakrishnan, SUNY at Buffalo</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Xiaodong Jiang, University of Georgia</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Chaochun Liu, JD Finance AI Lab</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Jiasen Lu, Georgia Institute of Technology</p>
			  </blockquote>
			  <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-2">Khorrami Pooya, MIT Lincoln Laboratory</p>
			  </blockquote>
		  </div>
			  
		<div class="col-sm-6 col-lg-6">
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Minghui Qiu, Alibaba</p>
		     </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Huan Sun, Ohio State University</p>
			 </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Mingming Sun, Baidu Research</p>
			 </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Zhiqiang Tao, Northeastern University</p>
			 </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Zhaowen Wang, Adobe Research</p>
			 </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Chenwei Zhang, University of Illinois at Chicago</p>
			 </blockquote>
			 <blockquote class="blockquote">
			  <p class="mb-0 col-lg-12 offset-lg-1">Handong Zhao, Adobe Research</p>
		     </blockquote>
            </div> 
          </div>
          
      </div>
	  </div>	  
		  
    </section>
    <div class="container"> </div>
    <footer class="text-center">
      <div class="container">
        <div class="row">
          <div class="col-12"> </div>
        </div>
      </div>
    </footer>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
    <script src="js/jquery-3.2.1.min.js"></script> 
    <!-- Include all compiled plugins (below), or include individual files as needed --> 
    <script src="js/popper.min.js"></script> 
    <script src="js/bootstrap-4.0.0.js"></script>
  </body>
</html>